# FastAPI performance test on GCP

**WARNING** : This folder is :construction: under construction :construction:

This repository is used to test **-FastAPI** performance on **GCP** with a basic API :
- GET request with user ID
- JSON response with user information:
    - first_name
    - last_name
    - email
    - living_city
    - living_country
    - birth_date
    - profession

The initial data is randomly generated with **faker** and inserted in databases for performance analysis:
- BigQuery
- CloudSQL
- AlloyDB

Some test will require cache with:
- Redis on Compute Engine (virtual machine)
- Memorycache (Redis managed by GCP)

## Testing protocol

Basic API with **FastAPI** using two routes:
- `/hello` that returns `Hello, World!` to test the API
- `/users/{user_id}` to get information about one user with its unique identifier

Data is generated by a Python script in the folder `0__generate_fake_data` and IDs list is stored in a **JSON** file to be used later.

Testing the API performance is done with `Locust` with a basic test: 
- Get the list containing all user identifiers
- Make API calls with random users

The testing protocol is the following:
- **FastAPI** running with **uvicorn** using 4 workers
- **Locust** will run several tests, each lasting 3 minutes:
    - 1 user doing request between 1 to 3 seconds
    - 20 users making simultaneous requests between 1 and 3 seconds per user
    - 50 users making simultaneous requests between 1 and 3 seconds per user
    - 100 users making simultaneous requests between 1 and 3 seconds per user

Locust will add 5 user each 5 seconds.

Each test result is exported for analysis

## How to use the repository?

Create a `.env` file at the root of the repository and insert requested environment variables:

```bash
GCP_PROJECT_ID="<GCP_PROJECT_NAME>"
GCP_REGION="<GCP_DEPLOYMENT_REGION>"
```

Then use these variables, the name is not important:

```bash
GCP_DATASET_ID="fake_data"
GCP_TABLE_ID="users"
GCP_GAR="test-api"
IMAGE_NAME="basic-api"
```

You have to install `uv`. If you are not using it yet (you should), see the documentation [here](https://docs.astral.sh/uv/getting-started/installation/).

Then create the virtual environment and sync dependancies: 

```bash
uv venv
uv sync
```

This will allow you to run the script to generate fake data:

```bash
uv run 0__generate_fake_data/main.py
```